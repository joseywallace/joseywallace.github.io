<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
  Jekyll integration by somiibo.com
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
--><html>
	<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<title>Multivariable Hierarchical Regression with Multiple Groups</title>
<meta name="description" content="">

<link rel="apple-touch-icon" sizes="180x180" href="/assets/icon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/icon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/icon/favicon-16x16.png">
<link rel="manifest" href="/assets/icon/manifest.json">
<link rel="mask-icon" href="/assets/icon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="/assets/icon/favicon.ico">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/v4-shims.css">
<meta name="msapplication-config" content="/assets/icon/browserconfig.xml">
<meta name="theme-color" content="#ffffff">

<!-- CSS -->
<link rel="stylesheet" href="/assets/css/main.css">
<noscript><link rel="stylesheet" href="/assets/css/noscript.css"></noscript>

	</head>
	<body class="is-loading">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Header -->
        <header id="header">
          <a href="/" class="logo">Joseph Wallace</a>
        </header>

				<!-- Nav -->
					<nav id="nav">

            <ul class="links">
  <li class=""><a href="/">Home</a></li>
  <li class=" active "><a href="/blog/">Blog</a></li>
  <li class=""><a href="/cv/">Curriculum Vitae</a></li>
</ul>


						<ul class="icons">
              <li><a href="https://linkedin.com/in/joseph-b-wallace/" class="icon fa-linkedin" rel="nofollow"><span class="label">LinkedIn</span></a></li>
              <li><a href="https://researchgate.net/profile/Joseph_Wallace5" class="fab fa-researchgate" rel="nofollow"><span class="label"></span></a></li>
              <li><a href="https://github.com/joseywallace" class="icon fa-github" rel="nofollow"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
				<div id="main">
          <section class="post">
    				<header class="major">
      				<span class="date">01 Sep 2018</span>
      				<h1>Multivariable Hierarchical Regression with Multiple Groups</h1>
      				<p>An example of multivariable hierarchical linear regression with multiple categories/groups in PyMC3</p>
      			</header>
      			<div class="image main"><img src="/images/2018-09-02_cover.png" alt=""></div>
      			<p></p>
<p>Bayesian hierarchical linear regression (BHLR) is a powerful tool for machine learning and statistical analysis. Indeed, the true power of Bayesian inference over so-called frequentist statistics really hit me the first time I built a hierarchical linear regressor. In contrast to frequentist linear regression, <strong>BHLR can integrate categorical data to a much deeper degree</strong>.</p>

<p>Frequentist linear regression can incorporate categorical data through a so-called one-hot-encoder, essentially creating a unique offset for each category. However, suppose that not only the offset between models changes, but also the correlation and slopes. In this case, the only choice is to split the data by category and train an entirely new model for each category. This can be especially detrimental if some categories have limited or noisy data. So the choices are (1) pool all the data together and loose most of the categorical dependence or (2) split the data by category and drastically reduce the volume of data for each model resulting in increased error. <strong>Neither of the frequentist regression options are suitable.</strong></p>

<p>Bayesian statistics offers a solution. BHLR models are able to account for the hierarchical structure of data. <strong>In this post, a BHLR is designed which maintains a separate slope/correlation for every category, but with the additional assumption that all slopes come from a common group distribution</strong>. This assumption allows the model to handle noisy data or lack of data within a particular category. If for example one category has limited/noisy data, then the slope will be pulled toward the mean slope across all other categories.</p>

<p>There is quite a bit of online material showing how to construct multivariable linear regressors and multi-categorical single metric linear regressors. However, I’m unaware of any post, tutorial, etc. showing the design of multivariable linear regressor with multiple groups. In this post, I show how to:</p>

<ol>
  <li>Create a multivariable linear regressor with multiple categories/groups</li>
  <li>Train the model</li>
  <li>Create  traceplot and summary statistics</li>
  <li>Run the model on test data</li>
</ol>

<h2 id="import-necessary-modules">Import necessary modules</h2>
<p>As in the previous example, we are again importing PyMC3 (Bayesian inference library) and Theano (deep learning library handling the back-end vector/matrix multiplications in PyMC3).</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-darkgrid'</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="create-the-data-set">Create the data set</h2>

<p>In this example we are using fake or simulated data. This approach will allow the reader to easily manipulate the input parameters (categories, features, data points) and visualize the effect on the model. The test data set is create using the equation below:</p>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_eq01.png" alt="">
</span>
</figure>

<p>Where, α is the intercept, <em>Noise</em> is the simulated noise in the data, β<sub>jk</sub> is the slope for feature j of category k, and <em>X</em><sub>ijk</sub> is the data value of category k for the jth feature of the ith data point).</p>

<p>In this example we create two features, four categories, and a thousand data points. Of course, the number of features, categories, and data points can be easily changed through their respective variables. It is important to note the way that the matrix of slope values is created. In this example, the slope for a given feature is chosen in the <em>feat_set</em> variable and then categorical variation is introduced through the <em>cat_set</em> variable. This means that the slopes across categories have a fixed average value. Such information will be important when constructing the hierarchical model.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">num_features</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_hierarchy</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">data_points</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">sigma_feat</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">sigma_cat</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">feat_set</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma_feat</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
	       <span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_hierarchy</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>   <span class="c"># create an array of feature values</span>
<span class="n">cat_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_hierarchy</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma_cat</span><span class="p">)</span>
<span class="n">beta_set</span> <span class="o">=</span> <span class="n">cat_set</span> <span class="o">+</span> <span class="n">feat_set</span>   <span class="c"># slope matrix of shape 'num_hierarchy X num_features'</span>
<span class="n">alpha_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c">#alpha value</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">data_points</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span> <span class="c">#shape:'data_points X num_features'</span>
<span class="n">cat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_hierarchy</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">data_points</span><span class="p">)</span> <span class="c">#shape:'data_points'</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span><span class="n">cat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">alpha_set</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">beta_set</span><span class="p">[</span><span class="n">cat</span><span class="p">]</span><span class="o">*</span><span class="n">X</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> 
	<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">data_points</span><span class="p">)))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c"># shape 'data_points X 1'</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">beta_set</span>
</code></pre>
</div>

<div class="highlighter-rouge">
<pre class="highlight"><code>array([[-1.25659813, -1.26705065],
       [-1.7186205 , -0.98422059],
       [-1.10539355, -0.51736205],
       [-1.33165915, -0.03235808]])
</code></pre>
</div>

<h2 id="visualize-the-data">Visualize the data</h2>

<p>Next, we can visualize the data using matplotlib via the python code below.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">category_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">category_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">category_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">category_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_1</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'1'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'^'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_2</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'2'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&gt;'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_3</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'3'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&lt;'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_4</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_4</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'4'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'o'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'X'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Y'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature 1'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_1</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'1'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'^'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_2</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'2'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&gt;'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_3</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'3'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&lt;'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">category_4</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">category_4</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'4'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'o'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'X'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature 2'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_1.png" alt="">
        <figcaption><b>Figure 1.</b> Plot of the simulated data for feature 1 (left) and 2 (right) for all four categories.</figcaption>
</span>
</figure>

<p>As shown in <strong>Fig. 1</strong>, feature 1 has a stronger correlation and larger slope compared to feature 2. The slopes across categories are distributed around a central value for each feature as expected from <strong>Eq. 1</strong> above.</p>

<h2 id="create-the-model">Create the model</h2>

<p>Next, we design the model. As demonstrated in “Doing Bayesian Analysis” by John Kruschke, hierarchical models are best conceptualized through illustration. <strong>Figure 2</strong>, below shows one of many possible solutions to create a linear regressor describing the data. Starting from the base we have the ith datum of category k, <em>y<sub>i,k</sub></em>, which is describe by the normal distribution <em>y<sub>like</sub> = N(μ, σ<sup>2</sup>)</em>. The σ of <em>y<sub>like</sub></em> is described through the half-normal distribution. The mean of <em>y<sub>like</sub></em> is described by the equation:</p>

<p style="text-align:center;"><img src="https://latex.codecogs.com/svg.latex?%5CLarge&amp;space;y_%7Best%7D=%5Calpha%20+%20%5Cbeta_%7B1,k%7DX_%7Bi1k%7D%20+%20%5Cbeta_%7B2,k%7DX_%7Bi2k%7D" title="eq_2" style="width:300px;height:50px;"></p>

<p>where α is the intercept, β<sub>j,k</sub> is the slope for the jth feature and kth category, and <em>x<sub>i,j,k</sub></em> is the ith value for category k and feature j. The offset, α, is described by a single common normal distribution across all categories. Note that the subscript of β<sub>j,k</sub> denotes the fact that each unique category/feature combination has its own slope. Above the equation for <em>y<sub>est</sub></em>, we see that the hierarchy splits into two main branches - one for each of the two features. The slopes for each feature/category combination are described by the normal distribution where <em>μ<sub>j,k</sub></em> and <em>σ<sub>j,k</sub></em> are the predicted mean and standard deviation. At the top level of the hierarchy, the distribution of mean slopes (<em>μ<sub>j,k</sub></em>) for all categories of a single feature come from a common normal distribution that acts as a generic vague prior.</p>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_model.PNG" alt="">
        <figcaption><b>Figure 2.</b> Model of dependencies for hierarchical linear regression with two features and multiple categories. The subscripts i, j, and k are the data point number, feature, and category, respectively. The subscripts 1 and 2 denote the feature type. The python variable names are given next to their respective variables.</figcaption>
</span>
</figure>

<p>The python code describing this hierarchy is shown below. The first few lines create the theano shared variables that will allow the training data to be switched out for the test data. All of the model parameters are then specified within the <em>with model</em> command. The code is written from the top of the hierarchy (<strong>Fig. 2</strong>), starting with hyper-priors <em>μ<sub>β</sub></em> and <em>σ<sub>β</sub></em> , down to the bottom of the hierarchy (<em>y<sub>ij</sub></em>). It should be noted that the python code implements Eq. 2 slightly different from (although mathematically equivalent to) how the equation is shown in the hierarchy. The actual code implements <em>y<sub>est</sub></em> as follows:
<br><br></p>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_eq02.png" alt="">
</span>
</figure>

<p>The variable α is represented by the single normal distribution. The variable, β<sub>j</sub>, is the jth element of the list comprehension, <em>beta</em>, describing the jth feature of the model. It is represented by the prior normal distributions and is of shape equal to the number of categories. For example, β<sub>j</sub>[0] would return the value for the jth feature and 0th category normal distribution). The variable <em>C<sub>k</sub></em> contains the category integer values (k) matching the category of <em>X<sub>ijk</sub></em>. Thus, <em>β<sub>j</sub>(C<sub>k</sub>)</em> results in an array of length equal to the total number of data points where the ith element is <em>β<sub>jk</sub></em> and <em>k</em> is the category associated with the ith data point <em>X<sub>ijk</sub></em>.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="c">#theano shared values to make switching out train/test data easy</span>
<span class="n">model_input_x</span> <span class="o">=</span> <span class="p">[</span><span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">model_input_cat</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model_output</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical_model</span><span class="p">:</span>
    <span class="c">#assume a beta mean/sigma distribution for each feature</span>
    <span class="n">mu_beta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu_beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
    <span class="n">sigma_beta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'sigma_beta'</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
    
    <span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_beta</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> 
            <span class="n">sd</span><span class="o">=</span><span class="n">sigma_beta</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_hierarchy</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_features</span><span class="p">)]</span>
    
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'eps'</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c"># Model error prior</span>
    
    <span class="n">y_est</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">([</span><span class="n">beta_i</span><span class="p">[</span><span class="n">model_input_cat</span><span class="p">]</span><span class="o">*</span><span class="n">model_input_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">beta_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta</span><span class="p">)])</span>
    
    <span class="n">y_ij</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y_like'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">y_est</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">model_output</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="train-the-model">Train the model</h2>

<p>Next, we train the model. In this example, I’m using the ADVI  – Automatic Differentation Variational Inference - inference method. We could also Use the NUTS - No U-Turn Sampler. However, ADVI is much faster and will scale better at larger numbers of categories and features.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="k">with</span> <span class="n">hierarchical_model</span><span class="p">:</span>    
    <span class="n">inference</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">ADVI</span><span class="p">()</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">n</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="n">inference</span><span class="p">,</span>
        <span class="p">)</span>
<span class="n">advi_trace</span> <span class="o">=</span> <span class="n">approx</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">7500</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge">
<pre class="highlight"><code>Average Loss = 1,107.6: 100%|██████████████████| 20000/20000 [00:20&lt;00:00, 957.51it/s]
Finished [100%]: Average Loss = 1,107.6
</code></pre>
</div>

<h2 id="traceplot-and-summary-table">Traceplot and summary table</h2>

<p>Once the model is trained we can plot the resulting trace plot (<strong>Fig. 3</strong>) using the python code below.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">advi_trace</span><span class="p">);</span>
</code></pre>
</div>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_trace.png" alt="">
        <figcaption><b>Figure 3.</b> Traceplot showing the resulting posterior distributions for each variable (left) and the sample value vs draw number (right). The blue and green colors in panels 1 and 4 are feature 1 and 2, respectively. Similarly, in panels 2 and 3, categories 1 through 4 are represented by colors blue, green, red, and purple, respectively.  </figcaption>
</span>
</figure>

<p>As shown in the <strong>Fig. 3</strong>, <em>mu_beta</em> (top panel) shows the posterior for the mean value across all categories for feature 1 (blue) and 2 (green). Panels 2 and 3 in <strong>Fig. 3</strong>, show the beta or slope posterior distributions where colors blue, green, red, and purple are the categories 1-4, respectively. The mean and standard deviation of each posterior can be displayed using the <em>pm.summary</em> command as shown below.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">advi_trace</span><span class="p">)</span>
</code></pre>
</div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>mc_error</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mu_beta__0</th>
      <td>-1.350242</td>
      <td>0.267692</td>
      <td>0.003006</td>
      <td>-1.874439</td>
      <td>-0.824122</td>
    </tr>
    <tr>
      <th>mu_beta__1</th>
      <td>-0.688267</td>
      <td>0.299188</td>
      <td>0.003707</td>
      <td>-1.277684</td>
      <td>-0.106423</td>
    </tr>
    <tr>
      <th>beta_0__0</th>
      <td>-1.372593</td>
      <td>0.084724</td>
      <td>0.001081</td>
      <td>-1.538209</td>
      <td>-1.207680</td>
    </tr>
    <tr>
      <th>beta_0__1</th>
      <td>-1.850151</td>
      <td>0.085407</td>
      <td>0.001001</td>
      <td>-2.017092</td>
      <td>-1.682500</td>
    </tr>
    <tr>
      <th>beta_0__2</th>
      <td>-1.175007</td>
      <td>0.084881</td>
      <td>0.000891</td>
      <td>-1.344568</td>
      <td>-1.011036</td>
    </tr>
    <tr>
      <th>beta_0__3</th>
      <td>-1.307591</td>
      <td>0.082486</td>
      <td>0.000857</td>
      <td>-1.470349</td>
      <td>-1.146790</td>
    </tr>
    <tr>
      <th>beta_1__0</th>
      <td>-1.192599</td>
      <td>0.081709</td>
      <td>0.000890</td>
      <td>-1.353531</td>
      <td>-1.036678</td>
    </tr>
    <tr>
      <th>beta_1__1</th>
      <td>-0.988164</td>
      <td>0.094933</td>
      <td>0.001124</td>
      <td>-1.180729</td>
      <td>-0.812796</td>
    </tr>
    <tr>
      <th>beta_1__2</th>
      <td>-0.571517</td>
      <td>0.093957</td>
      <td>0.001064</td>
      <td>-0.745138</td>
      <td>-0.379638</td>
    </tr>
    <tr>
      <th>beta_1__3</th>
      <td>-0.247489</td>
      <td>0.083901</td>
      <td>0.000928</td>
      <td>-0.411054</td>
      <td>-0.083529</td>
    </tr>
    <tr>
      <th>alpha__0</th>
      <td>-0.366627</td>
      <td>0.043910</td>
      <td>0.000481</td>
      <td>-0.454190</td>
      <td>-0.281669</td>
    </tr>
    <tr>
      <th>sigma_beta__0</th>
      <td>0.553647</td>
      <td>0.274729</td>
      <td>0.003117</td>
      <td>0.142453</td>
      <td>1.082682</td>
    </tr>
    <tr>
      <th>sigma_beta__1</th>
      <td>0.631549</td>
      <td>0.286647</td>
      <td>0.003291</td>
      <td>0.189442</td>
      <td>1.199908</td>
    </tr>
    <tr>
      <th>eps</th>
      <td>1.024429</td>
      <td>0.034206</td>
      <td>0.000437</td>
      <td>0.960880</td>
      <td>1.094541</td>
    </tr>
  </tbody>
</table>
</div>

<p>For comparison, the orginal beta/slope matrix used to generate the data is shown below.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">beta_set</span>
</code></pre>
</div>

<div class="highlighter-rouge">
<pre class="highlight"><code>array([[-1.25659813, -1.26705065],
       [-1.7186205 , -0.98422059],
       [-1.10539355, -0.51736205],
       [-1.33165915, -0.03235808]])
</code></pre>
</div>

<h2 id="test-the-trained-model-on-the-test-data">Test the trained model on the test data</h2>

<p>Now that the model is trained, the training data can be replaced with the test data for validation. The data swap is performed using the theano shared variable created earlier. Then, a posterior predictive check (ppc) is used to sample the space of test x values and generate predictions. For every test datum, the ppc draws 2000 samples. Thus, the resulting ppc is an array of shape <em>len(X_test) X 2000</em>.</p>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="c"># set the shared values to the test data</span>
<span class="p">[</span><span class="n">model_input_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">model_input_cat</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model_output</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="c">#create a posterior predictive check (ppc) to sample the space of test x values</span>
<span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_ppc</span><span class="p">(</span>
        <span class="n">advi_trace</span><span class="p">[</span><span class="mi">2000</span><span class="p">:],</span> <span class="c"># specify the trace and exclude the first 2000 samples </span>
        <span class="n">model</span><span class="o">=</span><span class="n">hierarchical_model</span><span class="p">,</span> <span class="c"># specify the trained model</span>
        <span class="n">samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span> <span class="c">#for each point in X_test, create 2000 samples</span>
</code></pre>
</div>

<div class="highlighter-rouge">
<pre class="highlight"><code>100%|█████████████████████████████████████████| 2000/2000 [00:00&lt;00:00, 2029.69it/s]
</code></pre>
</div>

<div class="language-python highlighter-rouge">
<pre class="highlight"><code><span class="n">category_1_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">category_2_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">category_3_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">category_4_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">ppc</span><span class="p">[</span><span class="s">'y_like'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c"># mean of the 2000 samples for each X_test datum</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">category_1_t</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="n">category_1_t</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'1'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'^'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">category_2_t</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="n">category_2_t</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'2'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&gt;'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">category_3_t</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="n">category_3_t</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'3'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'&lt;'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">category_4_t</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="n">category_4_t</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'4'</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'o'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'y estimate'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'y actual'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><strong>Figure 4</strong> show the y values from the test data as a function of the predicted values from the model. The R<sup>2</sup> between the actual y values and the predictions (calculated via <em>r2_score(y_test,pred)</em>) is 0.74.</p>

<figure>
<span class="image fit">
        <img src="/images/2018-09-02_pred.png" alt="">
        <figcaption><b>Figure 4.</b> Plot showing the actual value as a function of the model prediction for the hierarchical model.  </figcaption>
</span>
</figure>

<p>In this post, I showed how to create a hierarchical model with an arbitrary number of features and groups. Future work might involve implementing the model into a regular class that can be used seamlessly in Sklearn.</p>

<h2 id="useful-links">Useful Links</h2>
<p><a href="https://github.com/joseywallace">    Github Repository for this project</a> <br>
<a href="https://www.amazon.com/gp/product/0124058884/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0124058884&amp;linkCode=as2&amp;tag=doinbayedat0c-20&amp;linkId=WAVQPZWCZRW25W6A">    Doing Bayesian Analysis</a></p>


      		</section>

          <div class="comments-wrapper">
          <div id="disqus_thread"></div>
          <script>
              /**
               *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
               *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
               */

              var disqus_config = function () {
                  this.page.url = '/blog/bayesian-hierarchical-linear-regression/';  /*Replace PAGE_URL with your page's canonical URL variable*/
                  this.page.identifier = '/blog/bayesian-hierarchical-linear-regression/'; /*Replace PAGE_IDENTIFIER with your page's unique identifier variable*/
              };

              (function() {  /* dont endit below this line */
                  var d = document, s = d.createElement('script');

                  s.src = 'https://joseywallace.github.io.disqus.com/embed.js';

                  s.setAttribute('data-timestamp', +new Date());
                  (d.head || d.body).appendChild(s);
              })();
          </script>
          <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
        </div>
<!-- /.comments-wrapper -->


					<!-- Footer -->
						<footer>
              <ul class="actions">
                <li><a href="/blog/" class="button">The Blog</a></li>
              </ul>
						</footer>
					</div>

				<!-- Footer -->
        <footer id="footer">
  <section>
    <form method="POST" action="https://formspree.io/Josey.Wallace@gmail.com">
      <div class="field">
        <label for="name">Name</label>
        <input type="text" name="name" id="name">
      </div>
      <div class="field">
        <label for="email">Email</label>
        <input type="text" name="email" id="email">
      </div>
      <div class="field">
        <label for="message">Message</label>
        <textarea name="message" id="message" rows="3"></textarea>
      </div>
      <ul class="actions">
        <li><input type="submit" value="Send Message"></li>
      </ul>
    </form>
  </section>
  <section class="split contact">
    <section class="alt">
      <h3>Location</h3>
      <p>Silicon Valley, CA</p>
    </section>
    <section>
      <h3>Social</h3>
      <ul class="icons alt">
        
        <li><a href="https://www.linkedin.com/" class="icon fa-linkedin" rel="nofollow"><span class="label">LinkedIn</span></a></li>
        <li><a href="https://researchgate.net/profile/Joseph_Wallace5" class="fab fa-researchgate" rel="nofollow"><span class="label"></span></a></li>
        <li><a href="https://github.com/default" class="icon fa-github" rel="nofollow"><span class="label">GitHub</span></a></li>
      </ul>
    </section>
  </section>
</footer>
<!-- Copyright -->
<div id="copyright">
  <ul>
<li>© HTML5 UP</li>
<li>Design by <a href="https://html5up.net" rel="nofollow">HTML5 UP</a>
</li>
<li>Jekyll Integration by <a href="https://soundgrail.com">SoundGrail</a>
</li>
</ul>
</div>


			</div>

      <!-- Scripts -->
  		<!-- DYN -->
<script src="/assets/js/jquery.min.js"></script>
<script src="/assets/js/jquery.scrollex.min.js"></script>
<script src="/assets/js/jquery.scrolly.min.js"></script>
<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<script src="/assets/js/main.js"></script>

			<script async src="https://www.googletagmanager.com/gtag/js?id=default"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'default');
</script>


	</body>
</html>
